# OpenAI ì„ë² ë”© ì²˜ë¦¬ ì„œë¹„ìŠ¤
# - semantic_queryë¥¼ ë²¡í„°ë¡œ ë³€í™˜
# - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ ì¿¼ë¦¬ ë™ì‹œ ì„ë² ë”©

import openai
import asyncio
from typing import List
from loguru import logger
import os
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ config ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from config.settings import Settings

class EmbeddingService:
    """OpenAI ì„ë² ë”© APIë¥¼ ì‚¬ìš©í•œ ë²¡í„° ë³€í™˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        """ì´ˆê¸°í™”"""
        if api_key:
            self.api_key = api_key
        else:
            settings = Settings()
            self.api_key = settings.OPENAI_API_KEY
            
        self.client = openai.OpenAI(api_key=self.api_key)
        self.model = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-large")
        logger.info(f"âœ… ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {self.model}")
    
    async def create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ (ë°°ì¹˜ ì²˜ë¦¬)"""
        try:
            logger.info(f"ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘ - {len(texts)}ê°œ í…ìŠ¤íŠ¸")
            
            # OpenAI APIëŠ” ë™ê¸° í˜¸ì¶œì´ë¯€ë¡œ executorì—ì„œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                self._create_embeddings_sync, 
                texts
            )
            
            embeddings = [data.embedding for data in response.data]
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ - {len(embeddings)}ê°œ ë²¡í„°")
            return embeddings
            
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _create_embeddings_sync(self, texts: List[str]):
        """ë™ê¸° ì„ë² ë”© ìƒì„± (ë‚´ë¶€ ë©”ì„œë“œ)"""
        return self.client.embeddings.create(
            input=texts,
            model=self.model
        )
    
    async def create_single_embedding(self, text: str) -> List[float]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            logger.debug(f"ğŸ”„ ë‹¨ì¼ ì„ë² ë”© ìƒì„±: {text[:50]}...")
            
            embeddings = await self.create_embeddings([text])
            return embeddings[0]
            
        except Exception as e:
            logger.error(f"âŒ ë‹¨ì¼ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def create_semantic_embeddings(self, semantic_queries: List[str]) -> List[List[float]]:
        """ì˜ë¯¸ì  ì¿¼ë¦¬ë“¤ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (ë°ì´íŠ¸ ì½”ìŠ¤ íŠ¹í™”)"""
        try:
            logger.info(f"ğŸ¯ ì˜ë¯¸ì  ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± - {len(semantic_queries)}ê°œ")
            
            # ì¿¼ë¦¬ ì „ì²˜ë¦¬ (í•„ìš”ì‹œ)
            processed_queries = [self._preprocess_query(query) for query in semantic_queries]
            
            return await self.create_embeddings(processed_queries)
            
        except Exception as e:
            logger.error(f"âŒ ì˜ë¯¸ì  ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _preprocess_query(self, query: str) -> str:
        """ì¿¼ë¦¬ ì „ì²˜ë¦¬ (ë°ì´íŠ¸ ì½”ìŠ¤ ë§¥ë½ ì¶”ê°€)"""
        # í•„ìš”ì‹œ ë°ì´íŠ¸ ì½”ìŠ¤ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŒ
        return query.strip()
    
    def get_embedding_dimension(self) -> int:
        """ì„ë² ë”© ë²¡í„° ì°¨ì› ë°˜í™˜"""
        if self.model == "text-embedding-3-small":
            return 1536
        elif self.model == "text-embedding-3-large":
            return 3072  # Large ëª¨ë¸ ì°¨ì›
        elif self.model == "text-embedding-ada-002":
            return 1536
        else:
            return 3072  # ê¸°ë³¸ê°’ì„ Largeë¡œ ë³€ê²½
    
    async def test_connection(self) -> bool:
        """OpenAI API ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            test_embedding = await self.create_single_embedding("í…ŒìŠ¤íŠ¸")
            logger.info("âœ… OpenAI ì„ë² ë”© API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
        except Exception as e:
            logger.error(f"âŒ OpenAI ì„ë² ë”© API ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

# í¸ì˜ í•¨ìˆ˜
async def create_embedding_service() -> EmbeddingService:
    """ì„ë² ë”© ì„œë¹„ìŠ¤ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    service = EmbeddingService()
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    if not await service.test_connection():
        raise RuntimeError("ì„ë² ë”© ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    
    return service

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    async def test_embedding_service():
        try:
            service = EmbeddingService()
            
            # ë‹¨ì¼ ì„ë² ë”© í…ŒìŠ¤íŠ¸
            test_text = "í™ëŒ€ì—ì„œ ì»¤í”Œì´ ê°€ê¸° ì¢‹ì€ ë¡œë§¨í‹±í•œ íŒŒì¸ë‹¤ì´ë‹ ë ˆìŠ¤í† ë‘"
            embedding = await service.create_single_embedding(test_text)
            print(f"âœ… ë‹¨ì¼ ì„ë² ë”© ì„±ê³µ - ì°¨ì›: {len(embedding)}")
            
            # ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸
            test_texts = [
                "ë¡œë§¨í‹±í•œ ë¶„ìœ„ê¸°ì˜ ë ˆìŠ¤í† ë‘",
                "ì¡°ìš©í•œ ì™€ì¸ë°”",
                "ì»¤í”Œì´ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ë¬¸í™”ì‹œì„¤"
            ]
            embeddings = await service.create_embeddings(test_texts)
            print(f"âœ… ë°°ì¹˜ ì„ë² ë”© ì„±ê³µ - {len(embeddings)}ê°œ ë²¡í„°")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    asyncio.run(test_embedding_service())
