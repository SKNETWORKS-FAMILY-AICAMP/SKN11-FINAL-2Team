# ë²¡í„° ê²€ìƒ‰ ë¡œì§ ë° ì¬ì‹œë„ ì „ëµ (Top-K ìˆœì°¨ í™•ëŒ€) - ìµœì¢… ê°œì„ ì•ˆ
# - 'ë‹¨ì¼ ì§€ì—­' ê²€ìƒ‰ ì‹œ, location_analyzerê°€ ê²°ì •í•œ ë™ì  ê²€ìƒ‰ ë°˜ê²½ì„ ì‚¬ìš©
# - ì¡°í•©ì´ ë¶€ì¡±í•  ê²½ìš°, Top-Kë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ëŠ˜ë ¤ê°€ë©° ì¬ì‹œë„
# - ë°˜ê²½ í™•ëŒ€ëŠ” ëª¨ë“  Top-K ì‹œë„ í›„, ìµœí›„ì˜ ë³´ë£¨ë¡œë§Œ ì‚¬ìš©

import asyncio
from typing import List, Dict, Any
from loguru import logger
import os
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆë“¤ import
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.database.qdrant_client import get_qdrant_client

class VectorSearchResult:
    """ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë˜í¼"""
    def __init__(self, places: List[Dict], attempt: str, radius_used: int, top_k_used: int):
        self.places = places
        self.attempt = attempt
        self.radius_used = radius_used
        self.top_k_used = top_k_used

class SmartVectorSearchEngine:
    """ìŠ¤ë§ˆíŠ¸ ë²¡í„° ê²€ìƒ‰ ì—”ì§„ (Top-K ìˆœì°¨ í™•ëŒ€ ì „ëµ)"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.qdrant_client = get_qdrant_client()
        self.top_k_steps = [5, 8, 12] # ì¬ì‹œë„ ì‹œ ì‚¬ìš©í•  Top-K ê°’ë“¤ (ë” ì ì§„ì ì´ê³  íš¨ìœ¨ì )
        self.radius_expansion_factor = 1.5
        logger.info("âœ… ìŠ¤ë§ˆíŠ¸ ë²¡í„° ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ (Top-K ìˆœì°¨ í™•ëŒ€ ì „ëµ)")

    async def search_with_retry_logic(
        self,
        search_targets: List[Dict[str, Any]],
        embeddings: List[List[float]],
        location_analysis: Dict[str, Any]
    ) -> VectorSearchResult:
        """
        ìƒí™©ì— ë§ëŠ” ë™ì  ê²€ìƒ‰ ë°˜ê²½ì„ ì‚¬ìš©í•˜ê³ ,
        ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ Top-Kë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ëŠ˜ë ¤ ì¬ì‹œë„í•œë‹¤.
        """
        try:
            # 1. Top-K ìˆœì°¨ì  ì¬ì‹œë„
            for i, top_k in enumerate(self.top_k_steps):
                attempt_name = f"{i+1}ì°¨ (Top-K={top_k})"
                logger.info(f"â–¶ï¸  {attempt_name} ê²€ìƒ‰ ì‹œì‘")

                # location_analysisì—ì„œ ê²°ì •ëœ ë™ì  ê²€ìƒ‰ ë°˜ê²½ì„ ì‚¬ìš©
                search_results = await self._execute_search(search_targets, embeddings, location_analysis, top_k)

                if self._is_search_successful(search_results, len(search_targets)):
                    logger.info(f"âœ… {attempt_name} ê²€ìƒ‰ ì„±ê³µ - ì¶©ë¶„í•œ ì¥ì†Œ í™•ë³´")
                    # í´ëŸ¬ìŠ¤í„°ë³„ ë°˜ê²½ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì²«ë²ˆì§¸ í´ëŸ¬ìŠ¤í„°ì˜ ë°˜ê²½ì„ ëŒ€í‘œë¡œ ì‚¬ìš©
                    radius_used = location_analysis['clusters'][0].search_radius
                    return VectorSearchResult(search_results, attempt_name, radius_used, top_k)
                else:
                    logger.warning(f"âš ï¸ {attempt_name} ê²€ìƒ‰ ë¶ˆì¶©ë¶„, ë‹¤ìŒ ë‹¨ê³„ ì‹œë„")

            # 2. ìµœí›„ì˜ ë³´ë£¨: ë°˜ê²½ í™•ëŒ€ ì¬ì‹œë„
            logger.warning(f"ğŸš¨ ëª¨ë“  Top-K ì‹œë„ ì‹¤íŒ¨. ìµœí›„ì˜ ë³´ë£¨ (ë°˜ê²½ í™•ëŒ€) ì‹œë„")
            
            # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì˜ ë°˜ê²½ì„ 1.5ë°° í™•ëŒ€í•˜ì—¬ ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼ ìƒì„±
            expanded_location_analysis = self._expand_search_radius(location_analysis)
            final_top_k = self.top_k_steps[1] # ë°˜ê²½ í™•ëŒ€ ì‹œì—ëŠ” Top-K=5ë¡œ ê³ ì •
            attempt_name = f"ìµœí›„ (ë°˜ê²½ í™•ëŒ€, Top-K={final_top_k})"

            final_results = await self._execute_search(search_targets, embeddings, expanded_location_analysis, final_top_k)
            
            radius_used = expanded_location_analysis['clusters'][0].search_radius
            logger.info(f"âœ… {attempt_name} ê²€ìƒ‰ ì™„ë£Œ")
            return VectorSearchResult(final_results, attempt_name, radius_used, final_top_k)

        except Exception as e:
            logger.error(f"âŒ ìŠ¤ë§ˆíŠ¸ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return VectorSearchResult([], "ì‹¤íŒ¨", 0, 0)

    async def _execute_search(
        self,
        search_targets: List[Dict[str, Any]],
        embeddings: List[List[float]],
        location_analysis: Dict[str, Any],
        top_k: int
    ) -> List[Dict]:
        """ì‹¤ì œ DB ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
        all_places = []
        clusters = location_analysis['clusters']

        # ê° í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
        for cluster in clusters:
            # í´ëŸ¬ìŠ¤í„°ì— ì†í•œ íƒ€ê²Ÿë“¤ë§Œ í•„í„°ë§
            cluster_target_indices = [i for i, t in enumerate(search_targets) if self._is_target_in_cluster(t, cluster)]

            for i in cluster_target_indices:
                target = search_targets[i]
                embedding = embeddings[i]
                
                # location_analyzerê°€ ê²°ì •í•œ ë™ì  ê²€ìƒ‰ ë°˜ê²½ì„ ì‚¬ìš©!
                radius = cluster.search_radius

                search_results = await self.qdrant_client.search_with_geo_filter(
                    query_vector=embedding,
                    center_lat=cluster.center_lat,
                    center_lon=cluster.center_lon,
                    radius_meters=radius,
                    category=self._get_target_info(target, 'category'),
                    limit=top_k
                )

                for result in search_results:
                    result['search_sequence'] = self._get_target_info(target, 'sequence')
                    result['target_category'] = self._get_target_info(target, 'category')
                all_places.extend(search_results)
        
        logger.debug(f"   ê²€ìƒ‰ ì™„ë£Œ (Top-K={top_k}) - ì´ {len(all_places)}ê°œ ì¥ì†Œ ë°œê²¬")
        return all_places

    def _is_search_successful(self, places: List[Dict], target_count: int) -> bool:
        """ê²€ìƒ‰ ì„±ê³µ ì—¬ë¶€ íŒë‹¨ (ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìµœì†Œ 2ê°œ ì´ìƒ ê²°ê³¼ í™•ë³´)"""
        if not places:
            return False
        
        places_by_seq = {}
        for p in places:
            seq = p.get('search_sequence')
            if seq not in places_by_seq:
                places_by_seq[seq] = []
            places_by_seq[seq].append(p)
        
        # ëª¨ë“  ìš”ì²­ íƒ€ê²Ÿì— ëŒ€í•´ ê²°ê³¼ê°€ ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ê° ê²°ê³¼ê°€ ìµœì†Œ 2ê°œ ì´ìƒì¸ì§€ í™•ì¸
        if len(places_by_seq) < target_count:
            return False
        
        return all(len(p_list) >= 2 for p_list in places_by_seq.values())

    def _expand_search_radius(self, location_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì˜ ê²€ìƒ‰ ë°˜ê²½ì„ 1.5ë°° í™•ëŒ€"""
        expanded_analysis = location_analysis.copy()
        for cluster in expanded_analysis['clusters']:
            cluster.search_radius = int(cluster.search_radius * self.radius_expansion_factor)
        logger.info(f"ë°˜ê²½ í™•ëŒ€: {location_analysis['clusters'][0].search_radius}m -> {expanded_analysis['clusters'][0].search_radius}m")
        return expanded_analysis

    # --- Helper Functions ---
    def _get_target_info(self, target: Any, key: str) -> Any:
        if hasattr(target, key):
            return getattr(target, key)
        return target.get(key)

    def _is_target_in_cluster(self, target: Any, cluster: Any) -> bool:
        target_seq = self._get_target_info(target, 'sequence')
        for cluster_target in cluster.targets:
            if self._get_target_info(cluster_target, 'sequence') == target_seq:
                return True
        return False

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
VectorSearchEngine = SmartVectorSearchEngine
